nn_ops:
  ImageData:
    comment: "Image data tensor."
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "the input tensor."
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8
    attrs:
      input_format:
        comment:  |-
          "input_format of original image, accepted format is in the range of
          [YUV420SP_U8, YUV422SP_U8, AYUV444_U8, YUYV_U8, YUV400_U8, XRGB8888_U8, ARGB8888_U8]
          "
        type: STR
        required: true
      src_image_size_w:
        comment: "original image size width"
        type: INT
        required: true
      src_image_size_h:
        comment: "original image size height"
        type: INT
        required: true
      image_type:
        comment: "accepted type is in the range of [JPEG, BT_601_NARROW, BT_601_FULL, BT_709_NARROW], default as JPEG"
        type: STR
        default: "JPEG"
    examples: |-
      "    TensorDesc desc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::ImageData imageData = hiai::op::ImageData("Placeholder");
          imageData.update_input_desc_x(desc);
          imageData.set_attr_input_format("ARGB8888_U8");
          imageData.set_attr_src_image_size_w(64);
          imageData.set_attr_src_image_size_h(64);
      "

  DynamicImageData:
    comment: "Dynamic image data tensor."
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "the input tensor."
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8
    attrs:
      max_src_image_size:
        comment: "max src image size"
        type: INT
        required: true
      image_type:
        comment: "accepted type is in the range of [JPEG, BT_601_NARROW, BT_601_FULL, BT_709_NARROW], default as JPEG"
        type: STR
        default: "JPEG"
    examples: |-
      "    TensorDesc desc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::DynamicImageData imageData = hiai::op::DynamicImageData("Placeholder");
          imageData.update_input_desc_x(desc);
          imageData.set_attr_max_src_image_size(64);
          imageData.set_attr_image_type("JPEG");
      "

  ConfigData:
    comment: "Data tensor for dynamic aipp"
    add_version: 100.520.020.100
    inputs:
      x:
        comment: "Input tensor stored config data"
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "Output tensor"
        tensor_types: DT_UINT8
    attrs:
      type:
        comment:  |-
          "respresenting aipp function type. Support 7 types including
          hiai::op::ImageCropV2::TYPE
          hiai::op::ImageResizeV2::TYPE
          hiai::op::ImageChannelSwapV2::TYPE
          hiai::op::ImageDataTypeConvertionV2::TYPE
          hiai::op::ImageColorSpaceConvertionV2::TYPE
          hiai::op::ImageRotateV2::TYPE
          hiai::op::ImagePadV2::TYPE
          "
        type: STR
        required: true
      value:
        comment: "value for the elements of the output tensor."
        type: TENSOR
        default: ""
    examples: |-
      "    hiai::CropPara crop;
          crop.inputFormat = ImageFormat::INVALID;
          crop.cropStartPosW = 0;
          crop.cropStartPosH = 0;
          crop.cropSizeW = 240;
          crop.cropSizeH = 240;

          hiai::op::ConfigData cropConfig = hiai::CreateConfigData(crop, "cropConfig", hiai::op::ImageCropV2::TYPE);
          auto imageCropv2 = hiai::op::ImageCropV2("imageCropv2")
                             .set_input_x(x)
                             .set_input_param(cropConfig);

      "

  ImageCrop:
    comment: "Extract crop from the input image tensor."
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "the input tensor."
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor."
        tensor_types: DT_UINT8
    attrs:
      load_start_pos_h:
        comment: "Y-axis of top left corner"
        type: INT
        default: "0"
      load_start_pos_w:
        comment: "X-axis of top left corner"
        type: INT
        default: "0"
      crop_size_h:
        comment: "Crop height"
        type: INT
        required: true
      crop_size_w:
        comment: "Crop width"
        type: INT
        required: true
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::ImageData x = hiai::op::ImageData("x");
          x.update_input_desc_x(xDesc);
          x.set_attr_input_format("ARGB8888_U8");
          x.set_attr_src_image_size_w(64);
          x.set_attr_src_image_size_h(64);

          auto imageCrop = hiai::op::ImageCrop("imageCrop")
                           .set_input_x(x)
                           .set_attr_crop_size_h(64)
                           .set_attr_crop_size_w(64);
      "

  ImageChannelSwap:
    comment: "Change image channel before Color Space Convertion"
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "the input tensor."
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8
    attrs:
      rbuv_swap_switch:
        comment: "whether to change the channel of R&B or U&V"
        type: BOOL
        default: "false"
      ax_swap_switch:
        comment: "whether to change GBA to ARGB or YUVA to AYUV"
        type: BOOL
        default: "false"
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::ImageData x = hiai::op::ImageData("x");
          x.update_input_desc_x(xDesc);
          x.set_attr_input_format("ARGB8888_U8");
          x.set_attr_src_image_size_w(64);
          x.set_attr_src_image_size_h(64);

          auto imageChannelSwap = hiai::op::ImageChannelSwap("imageChannelSwap")
                                  .set_input_x(x)
                                  .set_attr_rbuv_swap_switch(false)
                                  .set_attr_ax_swap_switch(true);
      "

  ImageColorSpaceConvertion:
    comment:  |-
      "Support convert YUV444 to RGB888, RGB888 to YUV444.
      Set target_format, CSC_MATRIX and CSC_BIAS will be configured by system according to input_format,
      image_type and target_format.
      "
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "the input tensor."
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8
    attrs:
      target_format:
        comment:  |-
          "target_format after color space conversion, accepted format is in the range of
          [YVU444SP_U8, YUV444SP_U8, RGB888_U8, BGR888_U8, YUV400_U8]
          "
        type: STR
        required: true
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::ImageData x = hiai::op::ImageData("Placeholder");
          x.update_input_desc_x(xDesc);
          x.set_attr_input_format("ARGB8888_U8");
          x.set_attr_src_image_size_w(64);
          x.set_attr_src_image_size_h(64);

          auto imageColorSpaceConvertion = hiai::op::ImageColorSpaceConvertion("imageColorSpaceConvertion")
                                           .set_input_x(x)
                                           .set_attr_target_format("YVU444SP_U8");
      "

  ImageResize:
    comment: "Resize the input image tensor, It use bilinear or nearest neighbor algorithm to support scale up and down"
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "the input tensor."
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8
    attrs:
      resize_output_h:
        comment: "height after resize"
        type: INT
        required: true
      resize_output_w:
        comment: "width after resize"
        type: INT
        required: true
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 32, 32}), FORMAT_NCHW, DT_UINT8);
          hiai::op::ImageData x = hiai::op::ImageData("x");
          x.update_input_desc_x(xDesc);
          x.set_attr_input_format("ARGB8888_U8");
          x.set_attr_src_image_size_w(64);
          x.set_attr_src_image_size_h(64);

          auto imageResize = hiai::op::ImageResize("imageResize")
                            .set_input_x(x)
                            .set_attr_resize_output_h(32)
                            .set_attr_resize_output_w(32);
      "

  ImageDataTypeConversion:
    comment:  |-
      "AI core support feature map data type are: int8 and fp16. But image RGB888 or YUV444 data are all uint8 data type.
      So we need data type conversion.
      uint8->int8: pixel_out_chx(i) = pixel_in_chx(i) - mean_chn_i
      uint8->fp16: pixel_out_chx(i) = (pixel_in_chx(i) - mean_chn_i - min_chn_i) * var_reci_chn
      "
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "the input tensor."
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor."
        tensor_types: DT_UINT8, DT_INT8, DT_FLOAT
    attrs:
      mean_chn_0:
        comment: "Average value of channel 0"
        type: INT
        default: "0"
      mean_chn_1:
        comment: "Average value of channel 1"
        type: INT
        default: "0"
      mean_chn_2:
        comment: "Average value of channel 2"
        type: INT
        default: "0"
      mean_chn_3:
        comment: "Average value of channel 3"
        type: INT
        default: "0"
      min_chn_0:
        comment: "Minimum value of channel 0"
        type: FLOAT
        default: "0"
      min_chn_1:
        comment: "Minimum value of channel 1"
        type: FLOAT
        default: "0"
      min_chn_2:
        comment: "Minimum value of channel 2"
        type: FLOAT
        default: "0"
      min_chn_3:
        comment: "Minimum value of channel 3"
        type: FLOAT
        default: "0"
      var_reci_chn_0:
        comment: "Variance of channel 0"
        type: FLOAT
        default: "1.0"
      var_reci_chn_1:
        comment: "Variance of channel 1"
        type: FLOAT
        default: "1.0"
      var_reci_chn_2:
        comment: "Variance of channel 2"
        type: FLOAT
        default: "1.0"
      var_reci_chn_3:
        comment: "Variance of channel 3"
        type: FLOAT
        default: "1.0"
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::ImageData x = hiai::op::ImageData("x");
          x.update_input_desc_x(xDesc);
          x.set_attr_input_format("ARGB8888_U8");
          x.set_attr_src_image_size_w(64);
          x.set_attr_src_image_size_h(64);

          auto imageDataTypeConversion = hiai::op::ImageDataTypeConversion("imageDataTypeConversion")
                                         .set_input_x(x);
      "

  ImageRotation:
    comment: "Rotate the input image tensor, It use bilinear or nearest neighbor algorithm to support scale up and down"
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "the input tensor."
        tensor_types: DT_UINT8, DT_INT8, DT_FLOAT
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8, DT_INT8, DT_FLOAT
    attrs:
      rotation_angle:
        comment: "rotate degree"
        type: FLOAT
        required: true

  ImagePadding:
    comment: "Add padding to input image tensor"
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "the input tensor."
        tensor_types: DT_UINT8, DT_INT8, DT_FLOAT
    outputs:
      y:
        comment: "the output tensor."
        tensor_types: DT_UINT8, DT_INT8, DT_FLOAT
    attrs:
      left_padding_size:
        comment: "left padding size"
        type: INT
        default: "0"
      right_padding_size:
        comment: "right padding size"
        type: INT
        default: "0"
      top_padding_size:
        comment: "top padding size"
        type: INT
        default: "0"
      bottom_padding_size:
        comment: "bottom padding size"
        type: INT
        default: "0"
      padding_value_chn_0:
        comment: "channel 0 padding value"
        type: FLOAT
        default: "0"
      padding_value_chn_1:
        comment: "channel 1 padding value"
        type: FLOAT
        default: "0"
      padding_value_chn_2:
        comment: "channel 2 padding value"
        type: FLOAT
        default: "0"
      padding_value_chn_3:
        comment: "channel 3 padding value"
        type: FLOAT
        default: "0"
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::ImageData x = hiai::op::ImageData("x");
          x.update_input_desc_x(xDesc);
          x.set_attr_input_format("ARGB8888_U8");
          x.set_attr_src_image_size_w(64);
          x.set_attr_src_image_size_h(64);

          auto imagePadding = hiai::op::ImagePadding("imagePadding")
                             .set_input_x(x)
                             .set_attr_left_padding_size(30)
                             .set_attr_right_padding_size(30)
                             .set_attr_top_padding_size(30)
                             .set_attr_bottom_padding_size(30)
                             .set_padding_value_chn_0(20.0)
                             .set_padding_value_chn_1(20.0)
                             .set_padding_value_chn_2(20.0)
                             .set_padding_value_chn_3(20.0);
      "

  ImageCropV2:
    comment: "Extract crop from the input image tensor."
    add_version: 100.530.000.000
    inputs:
      x:
        comment: "the input tensor"
        tensor_types: DT_UINT8
      param:
        comment: "the crop param"
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          hiai::CropPara crop;
          crop.cropStartPosW = 0;
          crop.cropStartPosH = 0;
          crop.cropSizeW = 64;
          crop.cropSizeH = 64;

          hiai::op::Const cropConst = hiai::hiai::CreateConfigConst(crop, "cropConst", hiai::op::ImageCropV2::TYPE);
          auto imageCropv2 = hiai::op::ImageCropV2("imageCropv2")
                             .set_input_x(x)
                             .set_input_param(cropConst);

          hiai::op::ConfigData cropConfig = hiai::CreateConfigData(crop, "cropConfig", hiai::op::ImageCropV2::TYPE);
          auto imageCropv2 = hiai::op::ImageCropV2("imageCropv2")
                             .set_input_x(x)
                             .set_input_param(cropConfig);
      "

  ImageResizeV2:
    comment: "Resize the input image tensor, It use bilinear or nearest neighbor algorithm to support scale up and down"
    add_version: 100.530.000.000
    inputs:
      x:
        comment: "the input tensor"
        tensor_types: DT_UINT8
      param:
        comment: "resize parameters"
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          hiai::ResizePara resize;
          resize.resizeOutputSizeW = 64;
          resize.resizeOutputSizeW = 64;

          hiai::op::Const resizeConst = hiai::hiai::CreateConfigConst(resize, "resizeConst", hiai::op::ImageResizeV2::TYPE);
          auto imageResizev2= hiai::op::ImageResizeV2("imageResizev2")
                             .set_input_x(x)
                             .set_input_param(cropConst);

          hiai::op::ConfigData resizeConfig = hiai::CreateConfigData(resize, "resizeConfig", hiai::op::ImageResizeV2::TYPE);
          auto imageResizev2 = hiai::op::ImageCropV2("imageResizev2")
                             .set_input_x(x)
                             .set_input_param(resizeConfig);
      "

  ImageChannelSwapV2:
    comment: "Change image channel before Color Space Convertion"
    add_version: 100.530.000.000
    inputs:
      x:
        comment: "the input tensor"
        tensor_types: DT_UINT8
      param:
        comment: "channel swap parameters"
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          hiai::ChannelSwapPara channelSwap;
          channelSwap.imageFormat = ImageFormat::RGB888;
          channelSwap.rbuvSwapSwitch = true;
          channelSwap.axSwapSwitch = true;

          hiai::op::Const swapConst = hiai::hiai::CreateConfigConst(channelSwap, "swapConst", hiai::op::ImageChannelSwapV2::TYPE);
          auto channelSwapV2 = hiai::op::ImageChannelSwapV2("channelSwapV2")
                             .set_input_x(x)
                             .set_input_param(swapConst);

          hiai::op::ConfigData swapConfig = hiai::CreateConfigData(channelSwap, "swapConfig", hiai::op::ImageChannelSwapV2::TYPE);
          auto channelSwapV2 = hiai::op::ImageChannelSwapV2("channelSwapV2")
                             .set_input_x(x)
                             .set_input_param(swapConfig);
      "

  ImageColorSpaceConvertionV2:
    comment:  |-
      "Support convert YUV444 to RGB888, RGB888 to YUV444.
      Set target_format, CSC_MATRIX and CSC_BIAS will be configured by system according to input_format,
      image_type and target_format.
      "
    add_version: 100.530.000.000
    inputs:
      x:
        comment: "the input tensor"
        tensor_types: DT_UINT8
      param:
        comment: "color space convertion parameters"
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::Data x = hiai::op::Data("Placeholder");
          x.update_input_desc_x(xDesc);

          hiai::CscPara cscPara;
          cscPara.outputFormat = ImageFormat::YUV444SP;
          cscPara.imageColorSpace = ImageColorSpace::JPEG;

          hiai::op::Const cscConst =
               hiai::hiai::CreateConfigConst(cscPara, "cscConst", hiai::op::ImageColorSpaceConvertionV2::TYPE);
          auto colorSpaceConvertionV2 = hiai::op::ImageChannelSwapV2("channelSwapV2")
                             .set_input_x(x)
                             .set_input_param(cscConst);

          hiai::op::ConfigData cscConfig =
               hiai::CreateConfigData(cscPara, "cscConfig", hiai::op::ImageColorSpaceConvertionV2::TYPE);
          auto colorSpaceConvertionV2 = hiai::op::ImageChannelSwapV2("channelSwapV2")
                             .set_input_x(x)
                             .set_input_param(cscConfig);
      "

  ImageDataTypeConvertionV2:
    comment:  |-
      "AI core support feature map data type are: int8 and fp16. But image RGB888 or YUV444 data are all uint8 data type.
      So we need data type conversion.
      uint8->int8: pixel_out_chx(i) = pixel_in_chx(i) - mean_chn_i
      uint8->fp16: pixel_out_chx(i) = (pixel_in_chx(i) - mean_chn_i - min_chn_i) * var_reci_chn
      "
    add_version: 100.530.000.000
    inputs:
      x:
        comment: "the input tensor"
        tensor_types: DT_UINT8
      param:
        comment: "dataType convertion parameters"
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8, DT_INT8, DT_FLOAT
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          hiai::DtcPara dtcPara;
          dtcPara.pixelMeanChn0 = 0;
          dtcPara.pixelMeanChn1 = 1;
          dtcPara.pixelMeanChn2 = 2;
          dtcPara.pixelMeanChn3 = 3;
          dtcPara.pixelMinChn0 = 4.0f;
          dtcPara.pixelMinChn1 = 5.0f;
          dtcPara.pixelMinChn2 = 6.0f;
          dtcPara.pixelMinChn3 = 7.0f;
          dtcPara.pixelVarReciChn0 = 8.0f;
          dtcPara.pixelVarReciChn1 = 9.0f;
          dtcPara.pixelVarReciChn2 = 10.0f;
          dtcPara.pixelVarReciChn3 = 11.0f;

          hiai::op::Const dtcConst = hiai::hiai::CreateConfigConst(dtcPara, "dtcConst", hiai::op::ImageDataTypeConvertionV2::TYPE);
          auto dataTypeConvertionV2 = hiai::op::ImageDataTypeConvertionV2("dataTypeConvertionV2")
                             .set_input_x(x)
                             .set_input_param(dtcConst);

          hiai::op::ConfigData dtcConfig =
               hiai::CreateConfigData(dtcPara, "dtcConfig", hiai::op::ImageDataTypeConvertionV2::TYPE);
          auto dataTypeConvertionV2 = hiai::op::ImageDataTypeConvertionV2("dataTypeConvertionV2")
                             .set_input_x(x)
                             .set_input_param(dtcConfig);
      "

  ImageRotateV2:
    comment: "Rotate the input image tensor, It use bilinear or nearest neighbor algorithm to support scale up and down"
    add_version: 100.530.000.000
    inputs:
      x:
        comment: "the input tensor."
        tensor_types: DT_UINT8, DT_INT8, DT_FLOAT
      param:
        comment: "rotate parameters, not supported dynamic currently"
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor"
        tensor_types: DT_UINT8, DT_INT8, DT_FLOAT
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          hiai::RotatePara rotatePara;
          rotatePara.rotationAngle = 90.0f;
          rotatePara.rotate = true;

          hiai::op::Const rotateConst = hiai::hiai::CreateConfigConst(rotatePara, "rotateConst", hiai::op::ImageRotateV2::TYPE);
          auto rotateV2 = hiai::op::ImageRotateV2("rotateV2")
                             .set_input_x(x)
                             .set_input_param(rotateConst);
      "

  ImagePadV2:
    comment: "Add padding to input image tensor"
    add_version: 100.530.000.000
    inputs:
      x:
        comment: "the input tensor."
        tensor_types: DT_UINT8, DT_INT8, DT_FLOAT
      param:
        comment: "padding parameters"
        tensor_types: DT_UINT8
    outputs:
      y:
        comment: "the output tensor."
        tensor_types: DT_UINT8, DT_INT8, DT_FLOAT
    examples: |-
      "    TensorDesc xDesc(Shape({1, 3, 64, 64}), FORMAT_NCHW, DT_UINT8);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          hiai::PadPara padPara;
          padPara.paddingSizeTop = 10;
          padPara.paddingSizeBottom = 10;
          padPara.paddingSizeLeft = 20;
          padPara.paddingSizeRight = 20;

          hiai::op::Const padConst = hiai::hiai::CreateConfigConst(padPara, "padConst", hiai::op::ImagePadV2::TYPE);
          auto padV2 = hiai::op::ImagePadV2("padV2")
                             .set_input_x(x)
                             .set_input_param(padConst);

          hiai::op::ConfigData padConfig = hiai::CreateConfigData(padPara, "padConfig", hiai::op::ImagePadV2::TYPE);
          auto padV2 = hiai::op::ImagePadV2("padV2")
                             .set_input_x(x)
                             .set_input_param(padConfig);
      "

  CropAndResize:
    comment: "Extracts crops from the input image tensor and resizes them."
    add_version: 100.310.010.013
    inputs:
      x:
        comment: "4-D tensor"
        tensor_types: DT_FLOAT
      boxes:
        comment: "2-D tensor. boxes[1] must be equal to 4."
        tensor_types: DT_FLOAT
      box_index:
        comment:  |-
          "1-D tensor. The value of box_index[i] specifies the image that the i-th box refers to.
          box_index[0] must be equal to boxes[0].
          "
        tensor_types: DT_INT32
      crop_size:
        comment: "weight and height."
        tensor_types: DT_INT32
    outputs:
      y:
        comment: "Output tensor"
        tensor_types: DT_FLOAT
    attrs:
      extrapolation_value:
        comment: "Value for extrapolation, default 0."
        type: FLOAT
        default: "0"
      method:
        comment: "Sampling method for resizing either bilinear or nearest. Defaults to bilinear."
        type: STR
        default: "bilinear"
    examples: |-
      "    TensorDesc xDesc(Shape({4, 5, 6, 7}), FORMAT_NCHW, DT_FLOAT);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          TensorDesc boxesTensorDesc(Shape({5, 4}), FORMAT_NCHW, DT_FLOAT);
          TensorPtr boxesTensor = std::make_shared<hiai::Tensor>(boxesTensorDesc);
          vector<float> boxesValue(5 * 4, 0.0);
          boxesTensor->SetData((uint8_t*)boxesValue.data(), 5 * 4 * sizeof(float));
          auto boxes = hiai::op::Const("boxes").set_attr_value(boxesTensor);

          TensorDesc boxIndexTensorDesc(Shape({5}), FORMAT_NCHW, DT_INT32);
          TensorPtr boxIndexTensor = std::make_shared<hiai::Tensor>(boxIndexTensorDesc);
          vector<int32_t> boxIndexValue(5, 0);
          boxIndexTensor->SetData((uint8_t*)boxIndexValue.data(), 5 * sizeof(int32_t));
          auto boxIndex = hiai::op::Const("boxIndex").set_attr_value(boxIndexTensor);

          TensorDesc cropSizeTensorDesc(Shape({2}), FORMAT_NCHW, DT_INT32);
          TensorPtr cropSizeTensor = std::make_shared<hiai::Tensor>(cropSizeTensorDesc);
          vector<int32_t> cropSizeValue = {7, 8};
          cropSizeTensor->SetData((uint8_t*)cropSizeValue.data(), 2 * sizeof(int32_t));
          auto cropSize = hiai::op::Const("cropSize").set_attr_value(cropSizeTensor);

          auto cropAndResize = hiai::op::CropAndResize("cropAndResize")
                               .set_input_x(x)
                               .set_input_boxes(boxes)
                               .set_input_box_index(boxIndex)
                               .set_input_crop_size(cropSize)
                               .set_attr_extrapolation_value(0)
                               .set_attr_method("bilinear");
      "

  ROIAlignV2:
    comment: "Consumes an input tensor X and region of interests (rois) to apply pooling across each RoI."
    add_version: 100.500.010.010
    inputs:
      features:
        comment: "4-D feature map"
        tensor_types: DT_FLOAT
      rois:
        comment: "2-D tensor, regions of interest to pool over"
        tensor_types: DT_FLOAT
      rois_n:
        comment: "the number of RoI"
        tensor_types: DT_INT32
        optional: true
      batch_indices:
        comment: "1-D tensor of shape with each element denoting the index of the corresponding image in the batch."
        tensor_types: DT_INT32
        optional: true
    outputs:
      y:
        comment: "Output tensor"
        tensor_types: DT_FLOAT
    attrs:
      spatial_scale:
        comment:  |-
          "A scaling factor that maps the raw image coordinates to the input feature map coordinates,
          { spatial_scale }. Generally is{ 1.0f }.
          "
        type: LIST_FLOAT
        required: true
      pooled_height:
        comment: "Pooled output y's height."
        type: INT
        required: true
      pooled_width:
        comment: "Pooled output y's width."
        type: INT
        required: true
      sample_num:
        comment: "Number of sampling points, default 0."
        type: INT
        default: "0"
      roi_end_mode:
        comment:  |-
          "Used to determine whether roi_end_h / roi_end_w is incremented by 1,
          0: roi_end_h / roi_end_w does not add one, 1: roi_end_h / roi_end_w add one. Default is 1.
          "
        type: INT
        default: "1"
      mode:
        comment: "The pooling method. Two modes are supported: 'avg' and 'max'. Default is 'avg'."
        type: STR
        default: "avg"

  ResizeBilinear:
    comment: "Resizes images to 'size' using bilinear interpolation."
    add_version: 100.310.010.013
    inputs:
      x:
        comment: "4-D tensor"
        tensor_types: DT_FLOAT
      size:
        comment: "1-D tensor with shape [height, width], must be const op."
        tensor_types: DT_INT32
    outputs:
      y:
        comment: "Output tensor"
        tensor_types: DT_FLOAT
    attrs:
      align_corners:
        comment:  |-
          "If true, the centers of the 4 corner pixels of the input and output tensors
          are aligned, preserving the values at the corner pixels.
          "
        type: BOOL
        default: "false"
    examples: |-
      "    TensorDesc xDesc(Shape({4, 5, 6, 7}), FORMAT_NCHW, DT_FLOAT);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          TensorDesc sizeTensorDesc(Shape({2}), FORMAT_NCHW, DT_INT32);
          TensorPtr sizeTensor = std::make_shared<hiai::Tensor>(sizeTensorDesc);
          vector<int32_t> dataValue = {7, 8};
          sizeTensor->SetData((uint8_t*)dataValue.data(), 2 * sizeof(int32_t));
          auto size = hiai::op::Const("size").set_attr_value(sizeTensor);

          auto resizeBilinear = hiai::op::ResizeBilinear("resizeBilinear")
                                .set_input_x(x)
                                .set_input_size(size)
                                .set_attr_align_corners(false);
      "

  ResizeBilinearV2:
    comment: "Resizes images to 'size' using bilinear interpolation."
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "4-D tensor"
        tensor_types: DT_FLOAT
      size:
        comment: "1-D tensor with shape [height, width]"
        tensor_types: DT_INT32
    outputs:
      y:
        comment: "Output tensor"
        tensor_types: DT_FLOAT
    attrs:
      align_corners:
        comment:  |-
          "If true, the centers of the 4 corner pixels of the input and output tensors
          are aligned, preserving the values at the corner pixels.
          "
        type: BOOL
        default: "false"
      half_pixel_centers:
        comment:  |-
          "If true, the align_corners must be false. and this attr change the mapping way
          to src image, default value is false.
          "
        type: BOOL
        default: "false"
    examples: |-
      "    TensorDesc xDesc(Shape({4, 5, 6, 7}), FORMAT_NCHW, DT_FLOAT);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          TensorDesc sizeTensorDesc(Shape({2}), FORMAT_NCHW, DT_INT32);
          TensorPtr sizeTensor = std::make_shared<hiai::Tensor>(sizeTensorDesc);
          vector<int32_t> dataValue = {7, 8};
          sizeTensor->SetData((uint8_t*)dataValue.data(), 2 * sizeof(int32_t));
          auto size = hiai::op::Const("size").set_attr_value(sizeTensor);

          auto resizeBilinearV2 = hiai::op::ResizeBilinearV2("resizeBilinearV2")
                                 .set_input_x(x)
                                 .set_input_size(size)
                                 .set_attr_align_corners(false)
                                 .set_attr_half_pixel_centers(true);
      "

  ResizeNearestNeighbor:
    comment: "Resizes images to 'size' using nearest neighbor interpolation."
    add_version: 100.310.010.013
    inputs:
      x:
        comment: "4-D tensor"
        tensor_types: DT_FLOAT
      size:
        comment: "1-D of two elements"
        tensor_types: DT_INT32
    outputs:
      y:
        comment: "Output tensor"
        tensor_types: DT_FLOAT
    attrs:
      align_corners:
        comment:  |-
          "If true, the centers of the 4 corner pixels of the input and output tensors are aligned,
          preserving the values at the corner pixels. Defaults to false
          "
        type: BOOL
        default: "false"
    examples: |-
      "    TensorDesc xDesc(Shape({4, 5, 6, 7}), FORMAT_NCHW, DT_FLOAT);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          TensorDesc sizeTensorDesc(Shape({2}), FORMAT_NCHW, DT_INT32);
          TensorPtr sizeTensor = std::make_shared<hiai::Tensor>(sizeTensorDesc);
          vector<int32_t> dataValue = {7, 8};
          sizeTensor->SetData((uint8_t*)dataValue.data(), 2 * sizeof(int32_t));
          auto size = hiai::op::Const("size").set_attr_value(sizeTensor);

          auto resizeNearestNeighbor = hiai::op::ResizeNearestNeighbor("resizeNearestNeighbor")
                                       .set_input_x(x)
                                       .set_input_size(size)
                                       .set_attr_align_corners(false);
      "

  ResizeNearestNeighborV2:
    comment: "Resizes images to 'size' using nearest neighbor interpolation."
    add_version: 100.500.010.010
    inputs:
      x:
        comment: "4-D tensor"
        tensor_types: DT_FLOAT
      size:
        comment: "1-D of two elements"
        tensor_types: DT_INT32
    outputs:
      y:
        comment: "Output tensor"
        tensor_types: DT_FLOAT
    attrs:
      align_corners:
        comment:  |-
          "If true, the centers of the 4 corner pixels of the input and output tensors are aligned,
          preserving the values at the corner pixels. Defaults to false
          "
        type: BOOL
        default: "false"
      half_pixel_centers:
        comment:  |-
          "If true, the align_corners must be false. and this attr change the mapping way
          to src image, default value is false.
          "
        type: BOOL
        default: "false"

  Upsample:
    comment: "The operator is used to adjust the shape according to the stride_h and stride_w."
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "The input tensor of 4-D."
        tensor_types: DT_FLOAT
    outputs:
      y:
        comment: "The output tensor of 4-D."
        tensor_types: DT_FLOAT
    attrs:
      stride_h:
        comment: "Dimension-h amplification factor, must be greater than 0."
        type: INT
        default: "1"
      stride_w:
        comment: "Dimension-w amplification factor, must be greater than 0."
        type: INT
        default: "1"
      scale:
        comment: "Reserved attribute, not need to enter."
        type: FLOAT
        default: "1.0"
    examples: |-
      "    TensorDesc xDesc(Shape({4, 5, 6, 7}), FORMAT_NCHW, DT_FLOAT);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          auto upsample = hiai::op::Upsample("upsample")
                          .set_input_x(x)
                          .set_attr_stride_h(2)
                          .set_attr_stride_w(3);
      "

  Interp:
    comment: "Interpolation operation to adjust image shape."
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "4-D tensor with shape [batch, depth, height, width], and must be non const op."
        tensor_types: DT_FLOAT
    outputs:
      y:
        comment: "the output tensor of 4-D."
        tensor_types: DT_FLOAT
    attrs:
      height:
        comment: "height of output, must be greater than 0."
        type: INT
        default: "-1"
      width:
        comment: "width of output, must be greater than 0."
        type: INT
        default: "-1"
      shrink_factor:
        comment: "shrink factor, must be greater than 0."
        type: INT
        default: "-1"
      zoom_factor:
        comment: "zoom factor, must be greater than 0."
        type: INT
        default: "-1"
      pad_begin:
        comment: "padding at begin of input, must be less than or equal to 0."
        type: INT
        default: "0"
      pad_end:
        comment: "padding at end of input, must be less than or equal to 0."
        type: INT
        default: "0"
    examples: |-
      "    TensorDesc xDesc(Shape({4, 5, 6, 7}), FORMAT_NCHW, DT_FLOAT);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          shrink_factor:
          auto interp = hiai::op::Interp("interp")
                        .set_input_x(x)
                        .set_attr_shrink_factor(2)
                        .set_attr_pad_begin(0)
                        .set_attr_pad_end(-1);

          zoom_factor:
          auto interp = hiai::op::Interp("interp")
                        .set_input_x(x)
                        .set_attr_zoom_factor(2)
                        .set_attr_pad_begin(0)
                        .set_attr_pad_end(-1);

          shrink_factor/zoom_factor:
          auto interp = hiai::op::Interp("interp")
                        .set_input_x(x)
                        .set_attr_shrink_factor(2)
                        .set_attr_zoom_factor(3)
                        .set_attr_pad_begin(-1)
                        .set_attr_pad_end(-2);

          height/width:
          auto interp = hiai::op::Interp("interp")
                        .set_input_x(x)
                        .set_attr_height(7)
                        .set_attr_width(8)
                        .set_attr_pad_begin(0)
                        .set_attr_pad_end(-2);
      "

  Crop:
    comment: "To crop ,elements of the first input are selected to fit the dimensions of the second input."
    add_version: 100.320.010.010
    inputs:
      x:
        comment: "The tensor to be croped."
        tensor_types: DT_FLOAT, DT_INT32, DT_UINT8, DT_BOOL
      size:
        comment: "The size of the input x to be croped."
        tensor_types: DT_INT32
    outputs:
      y:
        comment: "The output tensor."
        tensor_types: DT_FLOAT, DT_INT32, DT_UINT8, DT_BOOL
    attrs:
      axis:
        comment: "The Dimension of input which to be croped."
        type: INT
        default: "2"
      offsets:
        comment: "The offsets of input x."
        type: LIST_INT
        required: true
    examples: |-
      "    TensorDesc xDesc(Shape({4, 5, 6, 7}), FORMAT_NCHW, DT_FLOAT);
          hiai::op::Data x = hiai::op::Data("x");
          x.update_input_desc_x(xDesc);

          TensorDesc sizeDesc(Shape({3, 4, 5, 6}), FORMAT_NCHW, DT_FLOAT);
          hiai::op::Data size = hiai::op::Data("size");
          size.update_input_desc_x(sizeDesc);

          auto crop = hiai::op::Crop("crop")
                      .set_input_x(x)
                      .set_input_size(size)
                      .set_attr_axis(0)
                      .set_attr_offsets({1, 1});
      "

  NonMaxSuppressionV3D:
    comment:  |-
      "Performs non-maximum suppression (NMS) on the boxes according to their intersection-over-union (IoU).
      NMS iteratively removes lower scoring boxes which have an IoU greater than iou_threshold
      with another (higher scoring) box.
      "
    add_version: 100.320.010.010
    inputs:
      boxes:
        comment:  |-
          "Non const op, should be 2-D tensor, dim[0] of boxes should be equal to dim[0] of scores,
          dim[1] of boxes should be 4.
          "
        tensor_types: DT_FLOAT
      scores:
        comment: "Non const op, should be 1-D tensor, dim[0] of scores should be equal to dim[0] of boxes."
        tensor_types: DT_FLOAT
    outputs:
      y:
        comment: "A 1-D integer tensor with the shape-value less than or equal to max_output_size."
        tensor_types: DT_INT32
    attrs:
      max_output_size:
        comment: "Meaning the maximum number of boxes to be selected by non max suppression."
        type: INT
        required: true
      iou_threshold:
        comment: "Meaning the threshold for deciding whether boxes overlap too much with respect to IOU."
        type: FLOAT
        required: true
      score_threshold:
        comment: "The threshold for deciding when to remove boxes based on score."
        type: FLOAT
        required: true

  NonMaxSuppressionV6:
    comment:  |-
      "Performs non-maximum suppression (NMS) on the boxes according to their intersection-over-union (IoU).
      NMS iteratively removes lower scoring boxes which have an IoU greater than iou_threshold
      with another (higher scoring) box.
      "
    add_version: 100.500.010.010
    inputs:
      boxes:
        comment:  |-
          "An input tensor with shape [num_batches, spatial_dimension, 4]. The single box data format is
          indicated by center_point_box.
          "
        tensor_types: DT_FLOAT
      scores:
        comment: "An input tensor with shape [num_batches, num_classes, spatial_dimension]"
        tensor_types: DT_FLOAT
      max_output_boxes_per_class:
        comment:  |-
          "Integer representing the maximum number of boxes to be selected per batch per class.
          It is a scalar. Only positive numbers(excluding 0) are supported, 1 for default.
          "
        tensor_types: DT_INT32
        optional: true
      iou_threshold:
        comment:  |-
          "Float representing the threshold for deciding whether boxes overlap too much with respect
          to IOU. It is scalar. Value range [0, 1].
          "
        tensor_types: DT_FLOAT
        optional: true
      score_threshold:
        comment:  |-
          "Float representing the threshold for deciding when to remove boxes based on score.
          It is a scalar.
          "
        tensor_types: DT_FLOAT
        optional: true
    outputs:
      selected_indices:
        comment:  |-
          "selected indices from the boxes tensor. [num_selected_indices, 3],
          the selected index format is [batch_index, class_index, box_index].
          "
        tensor_types: DT_INT32
    attrs:
      center_point_box:
        comment:  |-
          "Integer indicate the format of the box data.
          The default is 0. 0 - the box data is supplied as [y1, x1, y2, x2]
          where (y1, x1) and (y2, x2) are the coordinates of any diagonal pair of box corners and the
          coordinates can be provided as normalized (i.e., lying in the interval [0, 1]) or absolute.
          Mostly used for TF models. 1 - the box data is supplied as [x_center, y_center, width, height]
          Mostly used for Pytorch models.
          "
        type: INT
        default: "0"

